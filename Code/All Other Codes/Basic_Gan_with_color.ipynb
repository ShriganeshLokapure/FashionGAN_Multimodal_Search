{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbjvAzud67Np",
        "outputId": "a4ea5050-1a78-4c89-db87-c3d6f25b0b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Basic_Gan_Implementation_color_images"
      ],
      "metadata": {
        "id": "T3ORJ1V6FpN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import PIL\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class FashionIQ(torch.utils.data.Dataset):\n",
        "    \"\"\"FashionIQ dataset for image-based GAN training, robust against file errors.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, split='train', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.imgs = []\n",
        "        self._prepare_dataset()\n",
        "\n",
        "    def _prepare_dataset(self):\n",
        "        splits = ['train', 'val', 'test']\n",
        "        if self.split not in splits:\n",
        "            raise ValueError(f\"Invalid split: {self.split}. Choose from {splits}.\")\n",
        "\n",
        "        for category in os.listdir(self.root_dir):\n",
        "            category_dir = os.path.join(self.root_dir, category)\n",
        "            if os.path.isdir(category_dir):\n",
        "                self._load_data(category, category_dir)\n",
        "\n",
        "    def _load_data(self, category, category_dir):\n",
        "        json_file = f\"cap.{category}.{self.split}.json\"\n",
        "        json_path = os.path.join(self.root_dir, json_file)\n",
        "        if not os.path.exists(json_path):\n",
        "            print(f\"Skipping missing file: {json_path}\")\n",
        "            return\n",
        "\n",
        "        with open(json_path, 'r') as f:\n",
        "            captions_data = json.load(f)\n",
        "\n",
        "        for item in captions_data:\n",
        "            img_path = os.path.join(category_dir, f\"{item['candidate']}.jpg\")\n",
        "            if os.path.exists(img_path):\n",
        "                data = {'image_path': img_path}\n",
        "                self.imgs.append(data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.imgs[idx]\n",
        "        try:\n",
        "            image = PIL.Image.open(data['image_path']).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image\n",
        "        except UnidentifiedImageError:\n",
        "            print(f\"Warning: Skipping corrupt image file {data['image_path']}\")\n",
        "            return None  # Return None for corrupt images\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 1024, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1024, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(1024, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1)\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Optimizers\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Dataset and DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.CenterCrop(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "dataset_path = '/content/gdrive/MyDrive/dataset'  # Adjust this path to your dataset location\n",
        "train_dataset = FashionIQ(root_dir=dataset_path, split='train', transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 50\n",
        "print(\"Starting training loop...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for i, real_data in enumerate(train_loader):\n",
        "        if real_data is None:\n",
        "            continue  # Skip batches with None due to corrupt images\n",
        "        real_data = real_data.to(device)\n",
        "        batch_size = real_data.size(0)\n",
        "\n",
        "        # Train Discriminator\n",
        "        discriminator.zero_grad()\n",
        "        label = torch.full((batch_size,), 1, dtype=torch.float, device=device)\n",
        "        output = discriminator(real_data)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
        "        fake_data = generator(noise)\n",
        "        label.fill_(0)\n",
        "        output = discriminator(fake_data.detach())\n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        errD = errD_real + errD_fake\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Train Generator\n",
        "        generator.zero_grad()\n",
        "        label.fill_(1)\n",
        "        output = discriminator(fake_data)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}] Batch {i + 1}/{len(train_loader)} Loss_D: {errD.item()} Loss_G: {errG.item()}')\n",
        "\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1MxZS9DhCdq7",
        "outputId": "f4480c43-2ccd-4e74-be93-1ae5ced19ebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting training loop...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] Batch 1/218 Loss_D: 1.5410484075546265 Loss_G: 7.5607709884643555\n",
            "Epoch [1/50] Batch 2/218 Loss_D: 2.9235188961029053 Loss_G: 10.675596237182617\n",
            "Epoch [1/50] Batch 3/218 Loss_D: 0.561673641204834 Loss_G: 7.8566179275512695\n",
            "Epoch [1/50] Batch 4/218 Loss_D: 1.5778430700302124 Loss_G: 15.371644973754883\n",
            "Epoch [1/50] Batch 5/218 Loss_D: 0.641708254814148 Loss_G: 11.660337448120117\n",
            "Epoch [1/50] Batch 6/218 Loss_D: 0.3663507103919983 Loss_G: 12.618114471435547\n",
            "Epoch [1/50] Batch 7/218 Loss_D: 0.14332598447799683 Loss_G: 9.946295738220215\n",
            "Epoch [1/50] Batch 8/218 Loss_D: 1.1090538501739502 Loss_G: 20.663406372070312\n",
            "Epoch [1/50] Batch 9/218 Loss_D: 0.554741382598877 Loss_G: 20.672088623046875\n",
            "Epoch [1/50] Batch 10/218 Loss_D: 0.2787984013557434 Loss_G: 17.911479949951172\n",
            "Epoch [1/50] Batch 11/218 Loss_D: 0.03569328039884567 Loss_G: 10.094118118286133\n",
            "Epoch [1/50] Batch 12/218 Loss_D: 1.9408588409423828 Loss_G: 21.81173324584961\n",
            "Epoch [1/50] Batch 13/218 Loss_D: 0.31324902176856995 Loss_G: 22.649635314941406\n",
            "Epoch [1/50] Batch 14/218 Loss_D: 0.0385933592915535 Loss_G: 21.94234848022461\n",
            "Epoch [1/50] Batch 15/218 Loss_D: 0.1385938972234726 Loss_G: 20.723968505859375\n",
            "Epoch [1/50] Batch 16/218 Loss_D: 0.017149299383163452 Loss_G: 18.862455368041992\n",
            "Epoch [1/50] Batch 17/218 Loss_D: 0.00946264248341322 Loss_G: 16.17746353149414\n",
            "Epoch [1/50] Batch 18/218 Loss_D: 0.039780110120773315 Loss_G: 11.120719909667969\n",
            "Epoch [1/50] Batch 19/218 Loss_D: 0.17986562848091125 Loss_G: 17.553014755249023\n",
            "Epoch [1/50] Batch 20/218 Loss_D: 0.03103363700211048 Loss_G: 17.489717483520508\n",
            "Epoch [1/50] Batch 21/218 Loss_D: 0.18030600249767303 Loss_G: 14.605341911315918\n",
            "Epoch [1/50] Batch 22/218 Loss_D: 0.016317199915647507 Loss_G: 7.412862300872803\n",
            "Epoch [1/50] Batch 23/218 Loss_D: 2.97011399269104 Loss_G: 24.30219268798828\n",
            "Epoch [1/50] Batch 24/218 Loss_D: 0.8865450620651245 Loss_G: 24.473819732666016\n",
            "Warning: Skipping corrupt image file /content/gdrive/MyDrive/dataset/shirt/B005H131IA.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 171, in collate_tensor_fn\n    numel = sum(x.numel() for x in batch)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 171, in <genexpr>\n    numel = sum(x.numel() for x in batch)\nAttributeError: 'NoneType' object has no attribute 'numel'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b7c0752dbd22>\u001b[0m in \u001b[0;36m<cell line: 138>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training loop...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreal_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# Skip batches with None due to corrupt images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 171, in collate_tensor_fn\n    numel = sum(x.numel() for x in batch)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\", line 171, in <genexpr>\n    numel = sum(x.numel() for x in batch)\nAttributeError: 'NoneType' object has no attribute 'numel'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YDrN1oPaFoKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import PIL\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class FashionIQ(torch.utils.data.Dataset):\n",
        "    \"\"\"FashionIQ dataset for image-based GAN training, robust against file errors.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, split='train', transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.imgs = []\n",
        "        self._prepare_dataset()\n",
        "\n",
        "    def _prepare_dataset(self):\n",
        "        splits = ['train', 'val', 'test']\n",
        "        if self.split not in splits:\n",
        "            raise ValueError(f\"Invalid split: {self.split}. Choose from {splits}.\")\n",
        "\n",
        "        for category in os.listdir(self.root_dir):\n",
        "            category_dir = os.path.join(self.root_dir, category)\n",
        "            if os.path.isdir(category_dir):\n",
        "                self._load_data(category, category_dir)\n",
        "\n",
        "    def _load_data(self, category, category_dir):\n",
        "        json_file = f\"cap.{category}.{self.split}.json\"\n",
        "        json_path = os.path.join(self.root_dir, json_file)\n",
        "        if not os.path.exists(json_path):\n",
        "            print(f\"Skipping missing file: {json_path}\")\n",
        "            return\n",
        "\n",
        "        with open(json_path, 'r') as f:\n",
        "            captions_data = json.load(f)\n",
        "\n",
        "        for item in captions_data:\n",
        "            img_path = os.path.join(category_dir, f\"{item['candidate']}.jpg\")\n",
        "            if os.path.exists(img_path):\n",
        "                data = {'image_path': img_path}\n",
        "                self.imgs.append(data)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.imgs[idx]\n",
        "        try:\n",
        "            image = PIL.Image.open(data['image_path']).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image\n",
        "        except (UnidentifiedImageError, OSError):\n",
        "            print(f\"Warning: Skipping corrupt image file {data['image_path']}\")\n",
        "            return None  # Return None for corrupt images\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(100, 1024, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(1024, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1024, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(1024, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input).view(-1)\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Initialize models\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Optimizers\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Dataset and DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(64),\n",
        "    transforms.CenterCrop(64),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "dataset_path = '/content/gdrive/MyDrive/dataset'  # Adjust this path to your dataset location\n",
        "train_dataset = FashionIQ(root_dir=dataset_path, split='train', transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 50\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 500\n",
        "print(\"Starting training loop...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for i, real_data in enumerate(train_loader):\n",
        "        if real_data is None:\n",
        "            continue  # Skip batches with None due to corrupt images\n",
        "        real_data = real_data.to(device)\n",
        "        batch_size = real_data.size(0)\n",
        "\n",
        "        # Train Discriminator\n",
        "        discriminator.zero_grad()\n",
        "        label = torch.full((batch_size,), 1, dtype=torch.float, device=device)\n",
        "        output = discriminator(real_data)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "\n",
        "        noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
        "        fake_data = generator(noise)\n",
        "        label.fill_(0)\n",
        "        output = discriminator(fake_data.detach())\n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        errD = errD_real + errD_fake\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # Train Generator\n",
        "        generator.zero_grad()\n",
        "        label.fill_(1)\n",
        "        output = discriminator(fake_data)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}] Loss_D: {errD.item()} Loss_G: {errG.item()}')\n",
        "\n",
        "    # Generate a sample image after each epoch\n",
        "    with torch.no_grad():\n",
        "            fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
        "            fake = generator(fixed_noise).detach().cpu()\n",
        "    vutils.save_image(fake, f\"epoch_{epoch + 1}.png\", normalize=True)\n",
        "\n",
        "print(\"Training complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EnyyIXf_D8rx",
        "outputId": "82c99503-6881-40b6-f644-55bffc9045d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting training loop...\n",
            "Epoch [1/500] Loss_D: 1.9787514209747314 Loss_G: 0.6498876214027405\n",
            "Epoch [2/500] Loss_D: 0.5019299983978271 Loss_G: 2.8207039833068848\n",
            "Epoch [3/500] Loss_D: 1.1446751356124878 Loss_G: 0.8222211599349976\n",
            "Epoch [4/500] Loss_D: 0.7996985912322998 Loss_G: 2.5613584518432617\n",
            "Epoch [5/500] Loss_D: 0.7452030181884766 Loss_G: 2.865910053253174\n",
            "Epoch [6/500] Loss_D: 0.9504235982894897 Loss_G: 1.9435086250305176\n",
            "Epoch [7/500] Loss_D: 1.0805575847625732 Loss_G: 2.7965683937072754\n",
            "Epoch [8/500] Loss_D: 0.9529976844787598 Loss_G: 2.157181739807129\n",
            "Epoch [9/500] Loss_D: 2.755718946456909 Loss_G: 0.6446815729141235\n",
            "Epoch [10/500] Loss_D: 3.2558648586273193 Loss_G: 0.6228301525115967\n",
            "Epoch [11/500] Loss_D: 0.5228728652000427 Loss_G: 2.9994914531707764\n",
            "Epoch [12/500] Loss_D: 1.3940130472183228 Loss_G: 2.869013786315918\n",
            "Epoch [13/500] Loss_D: 0.8948913812637329 Loss_G: 2.015883207321167\n",
            "Epoch [14/500] Loss_D: 0.2810438275337219 Loss_G: 3.8624179363250732\n",
            "Epoch [15/500] Loss_D: 0.5764579176902771 Loss_G: 2.545473337173462\n",
            "Epoch [16/500] Loss_D: 0.6483763456344604 Loss_G: 3.658811092376709\n",
            "Epoch [17/500] Loss_D: 0.29030513763427734 Loss_G: 3.9317898750305176\n",
            "Epoch [18/500] Loss_D: 1.526047706604004 Loss_G: 0.8256377577781677\n",
            "Epoch [19/500] Loss_D: 0.26095354557037354 Loss_G: 4.284472942352295\n",
            "Epoch [20/500] Loss_D: 1.7614657878875732 Loss_G: 0.6673158407211304\n",
            "Epoch [21/500] Loss_D: 0.6784226894378662 Loss_G: 13.832196235656738\n",
            "Epoch [22/500] Loss_D: 0.6004053354263306 Loss_G: 4.5020670890808105\n",
            "Epoch [23/500] Loss_D: 0.2697034180164337 Loss_G: 8.353379249572754\n",
            "Epoch [24/500] Loss_D: 0.24153290688991547 Loss_G: 8.900556564331055\n",
            "Epoch [25/500] Loss_D: 0.8620811700820923 Loss_G: 0.4797801971435547\n",
            "Epoch [26/500] Loss_D: 0.6218057870864868 Loss_G: 6.088723659515381\n",
            "Epoch [27/500] Loss_D: 0.6326326727867126 Loss_G: 5.5074262619018555\n",
            "Epoch [28/500] Loss_D: 0.24963116645812988 Loss_G: 9.148900032043457\n",
            "Epoch [29/500] Loss_D: 0.16356168687343597 Loss_G: 5.544504642486572\n",
            "Epoch [30/500] Loss_D: 0.3064098060131073 Loss_G: 2.143245220184326\n",
            "Epoch [31/500] Loss_D: 1.8666374683380127 Loss_G: 0.044461846351623535\n",
            "Epoch [32/500] Loss_D: 0.11788010597229004 Loss_G: 5.469709396362305\n",
            "Epoch [33/500] Loss_D: 0.28277501463890076 Loss_G: 13.24738883972168\n",
            "Epoch [34/500] Loss_D: 0.2804385721683502 Loss_G: 4.0021185874938965\n",
            "Epoch [35/500] Loss_D: 0.3131325840950012 Loss_G: 12.218098640441895\n",
            "Epoch [36/500] Loss_D: 0.04847290739417076 Loss_G: 5.975876808166504\n",
            "Epoch [37/500] Loss_D: 0.48312705755233765 Loss_G: 12.980894088745117\n",
            "Epoch [38/500] Loss_D: 0.9915751814842224 Loss_G: 6.007345199584961\n",
            "Epoch [39/500] Loss_D: 0.07332997769117355 Loss_G: 5.866892337799072\n",
            "Epoch [40/500] Loss_D: 1.0723395347595215 Loss_G: 14.653802871704102\n",
            "Epoch [41/500] Loss_D: 0.16532565653324127 Loss_G: 7.379917144775391\n",
            "Epoch [42/500] Loss_D: 0.1644974946975708 Loss_G: 3.711531162261963\n",
            "Epoch [43/500] Loss_D: 1.9062228202819824 Loss_G: 33.72093963623047\n",
            "Epoch [44/500] Loss_D: 1.7470262050628662 Loss_G: 5.911479949951172\n",
            "Epoch [45/500] Loss_D: 0.4533570110797882 Loss_G: 0.7833206653594971\n",
            "Epoch [46/500] Loss_D: 0.2960302531719208 Loss_G: 3.369424343109131\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-881e4475ddff>\u001b[0m in \u001b[0;36m<cell line: 141>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training loop...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreal_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# Skip batches with None due to corrupt images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "        fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
        "        fake = generator(fixed_noise).detach().cpu()\n",
        "vutils.save_image(fake, f\"epoch_{epoch + 1}.png\", normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "O33Hay0vGCDT",
        "outputId": "eb023c9f-feb9-4207-a72f-2952b318fcf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    vutils.save_image(fake, f\"epoch_{epoch + 1}.png\", normalize=True)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "        fake = generator(fixed_input).detach().cpu()\n",
        "vutils.save_image(fake, f\"epoch_{epoch + 1}.png\", normalize=True)"
      ],
      "metadata": {
        "id": "dbFLb3_mHMT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}