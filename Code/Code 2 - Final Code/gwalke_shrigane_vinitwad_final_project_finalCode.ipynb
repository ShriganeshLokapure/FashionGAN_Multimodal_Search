{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting Google Drive in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdXc06QUY8kQ",
    "outputId": "9fa49a2f-d44b-4ea6-b043-8dcee03dc9df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shw9KY01Yzh7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shw9KY01Yzh7"
   },
   "outputs": [],
   "source": [
    "# Path to dataset\n",
    "dataset_path = '/content/drive/MyDrive/dataset'\n",
    "categories = ['dress', 'shirt', 'toptee']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shw9KY01Yzh7"
   },
   "outputs": [],
   "source": [
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shw9KY01Yzh7"
   },
   "outputs": [],
   "source": [
    "data_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data from Each Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shw9KY01Yzh7"
   },
   "outputs": [],
   "source": [
    "# Load data from each category\n",
    "for category in categories:\n",
    "    json_file = os.path.join(dataset_path, f'cap.{category}.train.json')\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    for item in data:\n",
    "        image_path = os.path.join(dataset_path, category, f\"{item['target']}.jpg\")\n",
    "        if os.path.exists(image_path):\n",
    "            image = Image.open(image_path)\n",
    "            image = transform(image)\n",
    "            data_list.append((image, item['captions']))\n",
    "        else:\n",
    "            print(f\"Image not found: {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Modules, Dataset, and Models Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Importing Libraries and Modules**: The code begins by importing necessary libraries and modules, including torch, torch.nn, DataLoader, Dataset from torch.utils.data, and BertModel, BertTokenizer from transformers.\n",
    "\n",
    "2. **Device Configuration**: It checks if a CUDA-enabled GPU is available and sets the device accordingly (either \"cuda\" or \"cpu\").\n",
    "\n",
    "3. **Custom Dataset Class (FashionDataset)**: This class defines a custom dataset for the fashion images and captions. It loads the data_list containing tuples of image paths and captions. The `getitem` method preprocesses the captions using a BERT tokenizer and returns the preprocessed data.\n",
    "\n",
    "4. **Generator Model**: The Generator class defines the generator model for the GAN. It consists of a BERT text encoder, an image encoder, a linear layer to match the number of channels in image features, and a decoder to reconstruct the image.\n",
    "\n",
    "5. **Discriminator Model**: The Discriminator class defines the discriminator model for the GAN. It consists of a series of convolutional layers followed by linear layers to classify whether an image is real or fake.\n",
    "\n",
    "6. **Initializing Models and Dataset**: It initializes the generator, discriminator, and the FashionDataset using the provided data_list. It also initializes the dataloader for batch processing.\n",
    "\n",
    "7. **Optimizers**: It defines Adam optimizers for both the generator and discriminator models.\n",
    "\n",
    "8. **Loss Function**: It defines the adversarial loss (BCELoss) for training the GAN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78z7HK51ZDO6",
    "outputId": "6fd7b39b-08e7-4033-d8ba-9c3cc9c61617"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Configuration for device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Custom Dataset Class\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data = data_list\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, captions = self.data[idx]\n",
    "        # If captions is a list, use the first caption. Adjust according to your data structure.\n",
    "        caption = captions[0] if isinstance(captions, list) else captions\n",
    "        encoded_captions = self.tokenizer(caption, return_tensors='pt', padding='max_length', truncation=True, max_length=128)\n",
    "        input_ids = encoded_captions['input_ids'].squeeze(0)  # Remove the batch dimension\n",
    "        attention_mask = encoded_captions['attention_mask'].squeeze(0)\n",
    "        return image, input_ids, attention_mask\n",
    "\n",
    "# Generator Model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.text_encoder = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "        self.image_encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        ).to(device)\n",
    "        \n",
    "        self.text_linear = nn.Linear(768, 256 * 64 * 64).to(device)  # Adjust the output size to match the size of image_features\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        text_features = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "        text_features = self.text_linear(text_features)  \n",
    "        text_features = text_features.view(text_features.size(0), 256, 64, 64)  # Reshape to match image_features\n",
    "        image_features = self.image_encoder(images)\n",
    "        combined_features = image_features + text_features\n",
    "        output = self.decoder(combined_features)\n",
    "        return output\n",
    "\n",
    "\n",
    "# Discriminator Model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 64 * 64, 1),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, images):\n",
    "        return self.model(images)\n",
    "\n",
    "# Initializing models and dataset\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "dataset = FashionDataset(data_list)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "adversarial_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below is training loop for a Generative Adversarial Network (GAN) designed for fashion image generation. The loop is structured to iterate over a specified number of epochs, with each epoch comprising a series of steps for training the discriminator and generator components of the GAN. \n",
    "\n",
    "During each iteration, the loop fetches batches of images, input IDs, and attention masks from the data loader, ensuring that these tensors are moved to the GPU if available for faster computation. The training process begins with training the discriminator. For this, it computes the loss on real images (`real_loss`) using real labels (assigned as 1), and on fake images (`fake_loss`) generated by the generator using fake labels (assigned as 0). The total discriminator loss (`d_loss`) is then calculated as the average of `real_loss` and `fake_loss`. The gradients of `d_loss` are used to update the discriminator's parameters, improving its ability to distinguish between real and generated images.\n",
    "\n",
    "Following the discriminator training, the loop proceeds to train the generator. It generates fake images using the generator and computes the generator loss (`g_loss`) based on the discriminator's output on these fake images. The gradients of `g_loss` are used to update the generator's parameters, enhancing its ability to generate more realistic images that can fool the discriminator. \n",
    "\n",
    "Throughout the training loop, the losses of both the discriminator and generator are printed for each epoch and batch, allowing for monitoring of the training progress. The loop concludes with a message indicating the completion of the training process, at which point the model should be trained and ready for evaluation or further use. Adjustments to the number of epochs and other parameters can be made as needed based on the specific requirements of the model and dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GYPJztuepFZ",
    "outputId": "b69b91b5-c434-4f6c-ad39-76cd99c1055f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss D: 0.5619608163833618, Loss G: 4.997202396392822\n",
      "Epoch [1/50], Loss D: 0.32781508564949036, Loss G: 3.6902079582214355\n",
      "Epoch [1/50], Loss D: 0.07392589747905731, Loss G: 2.5140812397003174\n",
      "Epoch [1/50], Loss D: 0.05293041467666626, Loss G: 2.6695785522460938\n",
      "Epoch [1/50], Loss D: 0.03877795487642288, Loss G: 3.571597099304199\n",
      "Epoch [2/50], Loss D: 0.017652057111263275, Loss G: 4.375607967376709\n",
      "Epoch [2/50], Loss D: 0.013916470110416412, Loss G: 4.827449798583984\n",
      "Epoch [2/50], Loss D: 0.0214516744017601, Loss G: 4.859555721282959\n",
      "Epoch [2/50], Loss D: 0.004736026283353567, Loss G: 4.957368850708008\n",
      "Epoch [2/50], Loss D: 0.014230530709028244, Loss G: 4.870750904083252\n",
      "Epoch [3/50], Loss D: 0.009708729572594166, Loss G: 4.836544990539551\n",
      "Epoch [3/50], Loss D: 0.006310194730758667, Loss G: 4.880497932434082\n",
      "Epoch [3/50], Loss D: 0.008388573303818703, Loss G: 4.929664611816406\n",
      "Epoch [3/50], Loss D: 0.010319022461771965, Loss G: 4.939871788024902\n",
      "Epoch [3/50], Loss D: 0.005403113551437855, Loss G: 4.992647171020508\n",
      "Epoch [4/50], Loss D: 0.006799775175750256, Loss G: 5.078134059906006\n",
      "Epoch [4/50], Loss D: 0.006187840364873409, Loss G: 5.164643287658691\n",
      "Epoch [4/50], Loss D: 0.0036388100124895573, Loss G: 5.304354667663574\n",
      "Epoch [4/50], Loss D: 0.009097812697291374, Loss G: 5.270454406738281\n",
      "Epoch [4/50], Loss D: 0.004078897647559643, Loss G: 5.318481922149658\n",
      "Epoch [5/50], Loss D: 0.00628689955919981, Loss G: 5.327652931213379\n",
      "Epoch [5/50], Loss D: 0.007018012925982475, Loss G: 5.324089050292969\n",
      "Epoch [5/50], Loss D: 0.0027596191503107548, Loss G: 5.389556884765625\n",
      "Epoch [5/50], Loss D: 0.002526909811422229, Loss G: 5.521526336669922\n",
      "Epoch [5/50], Loss D: 0.005350371822714806, Loss G: 5.550660610198975\n",
      "Epoch [6/50], Loss D: 0.002938890364021063, Loss G: 5.6522417068481445\n",
      "Epoch [6/50], Loss D: 0.002172514796257019, Loss G: 5.725929260253906\n",
      "Epoch [6/50], Loss D: 0.0052827512845396996, Loss G: 5.77659797668457\n",
      "Epoch [6/50], Loss D: 0.0030480874702334404, Loss G: 5.78177547454834\n",
      "Epoch [6/50], Loss D: 0.005992440972477198, Loss G: 5.697579383850098\n",
      "Epoch [7/50], Loss D: 0.0054644509218633175, Loss G: 5.606882095336914\n",
      "Epoch [7/50], Loss D: 0.0025519123300909996, Loss G: 5.629691123962402\n",
      "Epoch [7/50], Loss D: 0.0023447233252227306, Loss G: 5.70765495300293\n",
      "Epoch [7/50], Loss D: 0.0018438794650137424, Loss G: 5.8252058029174805\n",
      "Epoch [7/50], Loss D: 0.004393383394926786, Loss G: 5.874054908752441\n",
      "Epoch [8/50], Loss D: 0.0029166750609874725, Loss G: 5.8863205909729\n",
      "Epoch [8/50], Loss D: 0.001653373590670526, Loss G: 5.9401750564575195\n",
      "Epoch [8/50], Loss D: 0.003553047776222229, Loss G: 5.972146511077881\n",
      "Epoch [8/50], Loss D: 0.003905578050762415, Loss G: 5.972295761108398\n",
      "Epoch [8/50], Loss D: 0.001776697114109993, Loss G: 5.985657691955566\n",
      "Epoch [9/50], Loss D: 0.0013324673054739833, Loss G: 6.09271240234375\n",
      "Epoch [9/50], Loss D: 0.003539805533364415, Loss G: 6.0811309814453125\n",
      "Epoch [9/50], Loss D: 0.0027315597981214523, Loss G: 6.069515705108643\n",
      "Epoch [9/50], Loss D: 0.00166394654661417, Loss G: 6.133120536804199\n",
      "Epoch [9/50], Loss D: 0.002690669847652316, Loss G: 6.13932991027832\n",
      "Epoch [10/50], Loss D: 0.0016146397683769464, Loss G: 6.188084602355957\n",
      "Epoch [10/50], Loss D: 0.0011488681193441153, Loss G: 6.265376091003418\n",
      "Epoch [10/50], Loss D: 0.0023719207383692265, Loss G: 6.294827938079834\n",
      "Epoch [10/50], Loss D: 0.0017472319304943085, Loss G: 6.313328742980957\n",
      "Epoch [10/50], Loss D: 0.003693368285894394, Loss G: 6.271762847900391\n",
      "Epoch [11/50], Loss D: 0.002557532861828804, Loss G: 6.229620933532715\n",
      "Epoch [11/50], Loss D: 0.0019273448269814253, Loss G: 6.209174633026123\n",
      "Epoch [11/50], Loss D: 0.0016088909469544888, Loss G: 6.257534027099609\n",
      "Epoch [11/50], Loss D: 0.00130426324903965, Loss G: 6.33213996887207\n",
      "Epoch [11/50], Loss D: 0.002010455122217536, Loss G: 6.350702285766602\n",
      "Epoch [12/50], Loss D: 0.0021901563741266727, Loss G: 6.3376970291137695\n",
      "Epoch [12/50], Loss D: 0.0016678331885486841, Loss G: 6.380951881408691\n",
      "Epoch [12/50], Loss D: 0.0023690760135650635, Loss G: 6.394143104553223\n",
      "Epoch [12/50], Loss D: 0.0009589279070496559, Loss G: 6.418129920959473\n",
      "Epoch [12/50], Loss D: 0.0011638953583315015, Loss G: 6.469363212585449\n",
      "Epoch [13/50], Loss D: 0.0010887326207011938, Loss G: 6.551753044128418\n",
      "Epoch [13/50], Loss D: 0.001783879124559462, Loss G: 6.543863773345947\n",
      "Epoch [13/50], Loss D: 0.001284367055632174, Loss G: 6.590822219848633\n",
      "Epoch [13/50], Loss D: 0.00192228180821985, Loss G: 6.59267520904541\n",
      "Epoch [13/50], Loss D: 0.0014206897467374802, Loss G: 6.603342056274414\n",
      "Epoch [14/50], Loss D: 0.0014204204780980945, Loss G: 6.588582992553711\n",
      "Epoch [14/50], Loss D: 0.0010185919236391783, Loss G: 6.665436744689941\n",
      "Epoch [14/50], Loss D: 0.001938903471454978, Loss G: 6.6481146812438965\n",
      "Epoch [14/50], Loss D: 0.001587767037563026, Loss G: 6.605716705322266\n",
      "Epoch [14/50], Loss D: 0.000866131333168596, Loss G: 6.654130935668945\n",
      "Epoch [15/50], Loss D: 0.0009265842381864786, Loss G: 6.697957992553711\n",
      "Epoch [15/50], Loss D: 0.0012347373412922025, Loss G: 6.738760471343994\n",
      "Epoch [15/50], Loss D: 0.0007974507752805948, Loss G: 6.777039527893066\n",
      "Epoch [15/50], Loss D: 0.0018281013472005725, Loss G: 6.800503730773926\n",
      "Epoch [15/50], Loss D: 0.0014558006078004837, Loss G: 6.743710517883301\n",
      "Epoch [16/50], Loss D: 0.0008885575225576758, Loss G: 6.808697700500488\n",
      "Epoch [16/50], Loss D: 0.0006480822339653969, Loss G: 6.82758903503418\n",
      "Epoch [16/50], Loss D: 0.0015777696389704943, Loss G: 6.8322343826293945\n",
      "Epoch [16/50], Loss D: 0.0018406219314783812, Loss G: 6.782208442687988\n",
      "Epoch [16/50], Loss D: 0.0007958496571518481, Loss G: 6.802863121032715\n",
      "Epoch [17/50], Loss D: 0.0006506986683234572, Loss G: 6.82918119430542\n",
      "Epoch [17/50], Loss D: 0.0013765490148216486, Loss G: 6.843685150146484\n",
      "Epoch [17/50], Loss D: 0.001468409551307559, Loss G: 6.873101234436035\n",
      "Epoch [17/50], Loss D: 0.0007984499097801745, Loss G: 6.902124881744385\n",
      "Epoch [17/50], Loss D: 0.0009872139198705554, Loss G: 6.896564960479736\n",
      "Epoch [18/50], Loss D: 0.0009951582178473473, Loss G: 6.893210411071777\n",
      "Epoch [18/50], Loss D: 0.0006441762670874596, Loss G: 6.952792644500732\n",
      "Epoch [18/50], Loss D: 0.0013011712580919266, Loss G: 6.95521354675293\n",
      "Epoch [18/50], Loss D: 0.0007739525754004717, Loss G: 6.981223106384277\n",
      "Epoch [18/50], Loss D: 0.0011663720943033695, Loss G: 7.009100914001465\n",
      "Epoch [19/50], Loss D: 0.00112451845780015, Loss G: 6.985258102416992\n",
      "Epoch [19/50], Loss D: 0.0007364422781392932, Loss G: 6.988999366760254\n",
      "Epoch [19/50], Loss D: 0.0005060487892478704, Loss G: 7.044480800628662\n",
      "Epoch [19/50], Loss D: 0.001128889387473464, Loss G: 7.0589985847473145\n",
      "Epoch [19/50], Loss D: 0.0010453707072883844, Loss G: 7.067233085632324\n",
      "Epoch [20/50], Loss D: 0.0006751269102096558, Loss G: 7.10646915435791\n",
      "Epoch [20/50], Loss D: 0.000853019068017602, Loss G: 7.075190544128418\n",
      "Epoch [20/50], Loss D: 0.0005391352460719645, Loss G: 7.131158351898193\n",
      "Epoch [20/50], Loss D: 0.0011252531548961997, Loss G: 7.12994384765625\n",
      "Epoch [20/50], Loss D: 0.0010329873766750097, Loss G: 7.127657413482666\n",
      "Epoch [21/50], Loss D: 0.0007967180572450161, Loss G: 7.110167026519775\n",
      "Epoch [21/50], Loss D: 0.0009443298913538456, Loss G: 7.1378912925720215\n",
      "Epoch [21/50], Loss D: 0.0007078650523908436, Loss G: 7.144478797912598\n",
      "Epoch [21/50], Loss D: 0.0009458501008339226, Loss G: 7.174834251403809\n",
      "Epoch [21/50], Loss D: 0.0005552069051191211, Loss G: 7.1673173904418945\n",
      "Epoch [22/50], Loss D: 0.0014012000756338239, Loss G: 7.155790328979492\n",
      "Epoch [22/50], Loss D: 0.0006179040065035224, Loss G: 7.161530494689941\n",
      "Epoch [22/50], Loss D: 0.0007293979870155454, Loss G: 7.151064872741699\n",
      "Epoch [22/50], Loss D: 0.0005085815209895372, Loss G: 7.224964141845703\n",
      "Epoch [22/50], Loss D: 0.0004648695176001638, Loss G: 7.245851516723633\n",
      "Epoch [23/50], Loss D: 0.0009109242237173021, Loss G: 7.239693641662598\n",
      "Epoch [23/50], Loss D: 0.00047911430010572076, Loss G: 7.311727523803711\n",
      "Epoch [23/50], Loss D: 0.0010307891061529517, Loss G: 7.314682960510254\n",
      "Epoch [23/50], Loss D: 0.000668438384309411, Loss G: 7.270483016967773\n",
      "Epoch [23/50], Loss D: 0.00038403086364269257, Loss G: 7.322472095489502\n",
      "Epoch [24/50], Loss D: 0.0008072934579104185, Loss G: 7.315299987792969\n",
      "Epoch [24/50], Loss D: 0.0006503822514787316, Loss G: 7.323884010314941\n",
      "Epoch [24/50], Loss D: 0.000793379673268646, Loss G: 7.375706672668457\n",
      "Epoch [24/50], Loss D: 0.0005843160324729979, Loss G: 7.358209609985352\n",
      "Epoch [24/50], Loss D: 0.00042964608292095363, Loss G: 7.403721809387207\n",
      "Epoch [25/50], Loss D: 0.0004166405997239053, Loss G: 7.3938703536987305\n",
      "Epoch [25/50], Loss D: 0.0010283624287694693, Loss G: 7.416543960571289\n",
      "Epoch [25/50], Loss D: 0.0004965862026438117, Loss G: 7.448379993438721\n",
      "Epoch [25/50], Loss D: 0.000730138155631721, Loss G: 7.427988052368164\n",
      "Epoch [25/50], Loss D: 0.00042005052091553807, Loss G: 7.434690475463867\n",
      "Epoch [26/50], Loss D: 0.0007237021345645189, Loss G: 7.426943778991699\n",
      "Epoch [26/50], Loss D: 0.0003297997754998505, Loss G: 7.475202560424805\n",
      "Epoch [26/50], Loss D: 0.0007197844097390771, Loss G: 7.487603187561035\n",
      "Epoch [26/50], Loss D: 0.0007835966534912586, Loss G: 7.491982460021973\n",
      "Epoch [26/50], Loss D: 0.00036045542219653726, Loss G: 7.490359306335449\n",
      "Epoch [27/50], Loss D: 0.000545104150660336, Loss G: 7.485501289367676\n",
      "Epoch [27/50], Loss D: 0.0005350206047296524, Loss G: 7.541094779968262\n",
      "Epoch [27/50], Loss D: 0.0010355720296502113, Loss G: 7.498034954071045\n",
      "Epoch [27/50], Loss D: 0.0003162014181725681, Loss G: 7.5066399574279785\n",
      "Epoch [27/50], Loss D: 0.00034094692091457546, Loss G: 7.531342506408691\n",
      "Epoch [28/50], Loss D: 0.0004376163415145129, Loss G: 7.591442108154297\n",
      "Epoch [28/50], Loss D: 0.0005154521786607802, Loss G: 7.560309410095215\n",
      "Epoch [28/50], Loss D: 0.0006830345373600721, Loss G: 7.58289909362793\n",
      "Epoch [28/50], Loss D: 0.0006941987085156143, Loss G: 7.570772171020508\n",
      "Epoch [28/50], Loss D: 0.0002884352579712868, Loss G: 7.596787452697754\n",
      "Epoch [29/50], Loss D: 0.000604091736022383, Loss G: 7.604757785797119\n",
      "Epoch [29/50], Loss D: 0.00038283056346699595, Loss G: 7.608113765716553\n",
      "Epoch [29/50], Loss D: 0.0002767006808426231, Loss G: 7.656311511993408\n",
      "Epoch [29/50], Loss D: 0.0008046699222177267, Loss G: 7.648087978363037\n",
      "Epoch [29/50], Loss D: 0.0004205178702250123, Loss G: 7.652044773101807\n",
      "Epoch [30/50], Loss D: 0.0007253421936184168, Loss G: 7.665733337402344\n",
      "Epoch [30/50], Loss D: 0.0006125632207840681, Loss G: 7.599697113037109\n",
      "Epoch [30/50], Loss D: 0.00031925749499350786, Loss G: 7.655976295471191\n",
      "Epoch [30/50], Loss D: 0.00026912937755696476, Loss G: 7.672934532165527\n",
      "Epoch [30/50], Loss D: 0.0004498801426962018, Loss G: 7.666887283325195\n",
      "Epoch [31/50], Loss D: 0.0005510445917025208, Loss G: 7.727215766906738\n",
      "Epoch [31/50], Loss D: 0.0004404856590554118, Loss G: 7.682345867156982\n",
      "Epoch [31/50], Loss D: 0.00024939284776337445, Loss G: 7.735591888427734\n",
      "Epoch [31/50], Loss D: 0.0004365345521364361, Loss G: 7.773120880126953\n",
      "Epoch [31/50], Loss D: 0.0005763740045949817, Loss G: 7.727667808532715\n",
      "Epoch [32/50], Loss D: 0.000547697301954031, Loss G: 7.750327110290527\n",
      "Epoch [32/50], Loss D: 0.0005208373768255115, Loss G: 7.7674360275268555\n",
      "Epoch [32/50], Loss D: 0.000529188197106123, Loss G: 7.709366321563721\n",
      "Epoch [32/50], Loss D: 0.0003239604993723333, Loss G: 7.7333526611328125\n",
      "Epoch [32/50], Loss D: 0.00023861820227466524, Loss G: 7.775742530822754\n",
      "Epoch [33/50], Loss D: 0.0006310874596238136, Loss G: 7.780866622924805\n",
      "Epoch [33/50], Loss D: 0.00031364912865683436, Loss G: 7.777278900146484\n",
      "Epoch [33/50], Loss D: 0.0002441422257106751, Loss G: 7.791498184204102\n",
      "Epoch [33/50], Loss D: 0.0003825448511634022, Loss G: 7.842557907104492\n",
      "Epoch [33/50], Loss D: 0.0004851285775657743, Loss G: 7.8693084716796875\n",
      "Epoch [34/50], Loss D: 0.0004271770012564957, Loss G: 7.837851047515869\n",
      "Epoch [34/50], Loss D: 0.00022136993356980383, Loss G: 7.863821983337402\n",
      "Epoch [34/50], Loss D: 0.0006050067604519427, Loss G: 7.864560127258301\n",
      "Epoch [34/50], Loss D: 0.0005005851271562278, Loss G: 7.845212936401367\n",
      "Epoch [34/50], Loss D: 0.0002195683482568711, Loss G: 7.868274688720703\n",
      "Epoch [35/50], Loss D: 0.0003601336502470076, Loss G: 7.879280090332031\n",
      "Epoch [35/50], Loss D: 0.0002026181755354628, Loss G: 7.938559532165527\n",
      "Epoch [35/50], Loss D: 0.0002604081528261304, Loss G: 7.929347038269043\n",
      "Epoch [35/50], Loss D: 0.0004654984804801643, Loss G: 7.924821853637695\n",
      "Epoch [35/50], Loss D: 0.000604864617343992, Loss G: 7.930994987487793\n",
      "Epoch [36/50], Loss D: 0.0005665284115821123, Loss G: 7.907140731811523\n",
      "Epoch [36/50], Loss D: 0.0003408658958505839, Loss G: 7.898512840270996\n",
      "Epoch [36/50], Loss D: 0.00025209313025698066, Loss G: 7.8997697830200195\n",
      "Epoch [36/50], Loss D: 0.00043756223749369383, Loss G: 7.911927223205566\n",
      "Epoch [36/50], Loss D: 0.0002217418805230409, Loss G: 7.9300384521484375\n",
      "Epoch [37/50], Loss D: 0.00033525523031130433, Loss G: 7.928055763244629\n",
      "Epoch [37/50], Loss D: 0.00022773662931285799, Loss G: 7.9462809562683105\n",
      "Epoch [37/50], Loss D: 0.00022716191597282887, Loss G: 8.024894714355469\n",
      "Epoch [37/50], Loss D: 0.0005315031739883125, Loss G: 8.033249855041504\n",
      "Epoch [37/50], Loss D: 0.00041812320705503225, Loss G: 8.0032377243042\n",
      "Epoch [38/50], Loss D: 0.000189556521945633, Loss G: 8.010932922363281\n",
      "Epoch [38/50], Loss D: 0.00020735232101287693, Loss G: 8.036069869995117\n",
      "Epoch [38/50], Loss D: 0.0003339677641633898, Loss G: 8.072518348693848\n",
      "Epoch [38/50], Loss D: 0.0003153716679662466, Loss G: 8.038087844848633\n",
      "Epoch [38/50], Loss D: 0.0006286167772486806, Loss G: 8.041488647460938\n",
      "Epoch [39/50], Loss D: 0.00029989518225193024, Loss G: 8.03109359741211\n",
      "Epoch [39/50], Loss D: 0.0004165515420027077, Loss G: 7.993268966674805\n",
      "Epoch [39/50], Loss D: 0.0004188561288174242, Loss G: 8.028881072998047\n",
      "Epoch [39/50], Loss D: 0.00028189236763864756, Loss G: 8.045013427734375\n",
      "Epoch [39/50], Loss D: 0.00019299483392387629, Loss G: 8.008185386657715\n",
      "Epoch [40/50], Loss D: 0.00020841002697125077, Loss G: 8.081724166870117\n",
      "Epoch [40/50], Loss D: 0.00018545292550697923, Loss G: 8.068299293518066\n",
      "Epoch [40/50], Loss D: 0.00019008950039278716, Loss G: 8.127140045166016\n",
      "Epoch [40/50], Loss D: 0.0004855743609368801, Loss G: 8.133426666259766\n",
      "Epoch [40/50], Loss D: 0.00048784539103507996, Loss G: 8.10982894897461\n",
      "Epoch [41/50], Loss D: 0.00028920918703079224, Loss G: 8.09994888305664\n",
      "Epoch [41/50], Loss D: 0.0003923836920876056, Loss G: 8.112138748168945\n",
      "Epoch [41/50], Loss D: 0.00028349709464237094, Loss G: 8.067716598510742\n",
      "Epoch [41/50], Loss D: 0.00016272220818791538, Loss G: 8.143396377563477\n",
      "Epoch [41/50], Loss D: 0.0003614298184402287, Loss G: 8.09896469116211\n",
      "Epoch [42/50], Loss D: 0.0003026275662705302, Loss G: 8.119985580444336\n",
      "Epoch [42/50], Loss D: 0.0005309977568686008, Loss G: 8.11031723022461\n",
      "Epoch [42/50], Loss D: 0.00016037064779084176, Loss G: 8.143705368041992\n",
      "Epoch [42/50], Loss D: 0.0002624631451908499, Loss G: 8.128917694091797\n",
      "Epoch [42/50], Loss D: 0.00018410233315080404, Loss G: 8.122014999389648\n",
      "Epoch [43/50], Loss D: 0.0001851874403655529, Loss G: 8.198495864868164\n",
      "Epoch [43/50], Loss D: 0.00017753939027898014, Loss G: 8.1786527633667\n",
      "Epoch [43/50], Loss D: 0.0002560638531576842, Loss G: 8.233158111572266\n",
      "Epoch [43/50], Loss D: 0.0004280091670807451, Loss G: 8.252510070800781\n",
      "Epoch [43/50], Loss D: 0.0003417092375457287, Loss G: 8.188920974731445\n",
      "Epoch [44/50], Loss D: 0.00026162900030612946, Loss G: 8.212206840515137\n",
      "Epoch [44/50], Loss D: 0.00014511810149997473, Loss G: 8.261690139770508\n",
      "Epoch [44/50], Loss D: 0.00025162682868540287, Loss G: 8.221199035644531\n",
      "Epoch [44/50], Loss D: 0.00035606115125119686, Loss G: 8.239354133605957\n",
      "Epoch [44/50], Loss D: 0.0003210922877769917, Loss G: 8.238176345825195\n",
      "Epoch [45/50], Loss D: 0.00017883906548377126, Loss G: 8.242923736572266\n",
      "Epoch [45/50], Loss D: 0.00030567069188691676, Loss G: 8.282297134399414\n",
      "Epoch [45/50], Loss D: 0.00040563440416008234, Loss G: 8.248066902160645\n",
      "Epoch [45/50], Loss D: 0.0001500546932220459, Loss G: 8.25363540649414\n",
      "Epoch [45/50], Loss D: 0.0002515653904993087, Loss G: 8.23275375366211\n",
      "Epoch [46/50], Loss D: 0.00023322431661654264, Loss G: 8.276931762695312\n",
      "Epoch [46/50], Loss D: 0.00016758241690695286, Loss G: 8.314810752868652\n",
      "Epoch [46/50], Loss D: 0.00031319697154685855, Loss G: 8.294962882995605\n",
      "Epoch [46/50], Loss D: 0.0002998245763592422, Loss G: 8.30150032043457\n",
      "Epoch [46/50], Loss D: 0.00023282834445126355, Loss G: 8.274654388427734\n",
      "Epoch [47/50], Loss D: 0.00024910588399507105, Loss G: 8.32798957824707\n",
      "Epoch [47/50], Loss D: 0.00022369726502802223, Loss G: 8.318391799926758\n",
      "Epoch [47/50], Loss D: 0.00044561081449501216, Loss G: 8.300086975097656\n",
      "Epoch [47/50], Loss D: 0.00014581854338757694, Loss G: 8.27438735961914\n",
      "Epoch [47/50], Loss D: 0.00014681217726320028, Loss G: 8.319343566894531\n",
      "Epoch [48/50], Loss D: 0.0002413655020063743, Loss G: 8.359007835388184\n",
      "Epoch [48/50], Loss D: 0.00013670937914866954, Loss G: 8.36134147644043\n",
      "Epoch [48/50], Loss D: 0.00021168873354326934, Loss G: 8.37847900390625\n",
      "Epoch [48/50], Loss D: 0.0002914392971433699, Loss G: 8.376911163330078\n",
      "Epoch [48/50], Loss D: 0.0002870584139600396, Loss G: 8.355171203613281\n",
      "Epoch [49/50], Loss D: 0.00028051043045707047, Loss G: 8.379755020141602\n",
      "Epoch [49/50], Loss D: 0.00021275457402225584, Loss G: 8.350105285644531\n",
      "Epoch [49/50], Loss D: 0.0003483314940240234, Loss G: 8.395821571350098\n",
      "Epoch [49/50], Loss D: 0.0001560040982440114, Loss G: 8.362473487854004\n",
      "Epoch [49/50], Loss D: 0.0001368625380564481, Loss G: 8.387186050415039\n",
      "Epoch [50/50], Loss D: 0.00020038464572280645, Loss G: 8.409034729003906\n",
      "Epoch [50/50], Loss D: 0.00040695536881685257, Loss G: 8.398578643798828\n",
      "Epoch [50/50], Loss D: 0.00020690745441243052, Loss G: 8.393522262573242\n",
      "Epoch [50/50], Loss D: 0.00014022043615113944, Loss G: 8.376518249511719\n",
      "Epoch [50/50], Loss D: 0.00014458959049079567, Loss G: 8.450642585754395\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 50  \n",
    "for epoch in range(num_epochs):\n",
    "    for images, input_ids, attention_mask in dataloader:\n",
    "        # Ensure all tensors are on the GPU if available\n",
    "        images = images.to(device)\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        real_labels = torch.ones(images.size(0), 1, device=device)\n",
    "        fake_labels = torch.zeros(images.size(0), 1, device=device)\n",
    "\n",
    "        # Train Discriminator: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Compute the discriminator losses on real images\n",
    "        real_output = discriminator(images)\n",
    "        real_loss = adversarial_loss(real_output, real_labels)\n",
    "\n",
    "        # Generate fake images\n",
    "        fake_images = generator(images, input_ids, attention_mask)\n",
    "        fake_output = discriminator(fake_images.detach())\n",
    "        fake_loss = adversarial_loss(fake_output, fake_labels)\n",
    "\n",
    "        # Backpropagate the total discriminator loss\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train Generator: maximize log(D(G(z)))\n",
    "        optimizer_G.zero_grad()\n",
    "        output = discriminator(fake_images)  # This time do not detach\n",
    "        g_loss = adversarial_loss(output, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss D: {d_loss.item()}, Loss G: {g_loss.item()}')\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decreasing loss in the generator (Loss G) and the discriminator (Loss D) suggests that the model is learning to generate more realistic images over time. In the initial epochs, both losses are relatively high, indicating that the generator is struggling to produce convincing images, and the discriminator is having difficulty distinguishing between real and generated images. However, as training progresses, both losses decrease, indicating that the generator is improving its ability to generate realistic images, and the discriminator is becoming more accurate in distinguishing between real and fake images. This trend suggests that the model is learning effectively and is on the right track to produce high-quality generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
